# -*- coding: utf-8 -*-
"""Assign(7).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fHownfOStqYzL8FBCRLl84hMT__iCfXF
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error

df=pd.read_csv('ToyotaCorolla - MLR.csv')

df.shape

df.head()

df.info()

df.isnull().sum()

df.isnull().sum().sum()

df.isnull().sum().sum()/len(df)*100

df.duplicated().sum()

df.drop_duplicates(inplace=True,ignore_index=True)

df.duplicated().sum()

# Numeric columns for EDA
numeric_cols = ['Price', 'Age_08_04', 'KM', 'HP', 'cc', 'Doors', 'Gears', 'Weight']
numeric_cols = [col for col in numeric_cols if col in df.columns]

# Histograms
plt.figure(figsize=(15, 10))
df[numeric_cols].hist(bins=20, edgecolor='black', alpha=0.5, figsize=(10, 8))
plt.tight_layout()
plt.show()

# Correlation heatmap
plt.figure(figsize=(10, 5))
sns.heatmap(df[numeric_cols].corr(), annot=True, fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

#Categorical variables
for col in ['Fuel_Type', 'Automatic']:
    if col in df.columns:
        print(f"{col}: {df[col].value_counts()}")

# Outlier_capping
def outlier_capping(df, columns):
    df_clean = df.copy()
    n_outliers = 0
    for col in columns:
        if col in df_clean.columns:
            Q1 = df_clean[col].quantile(0.25)
            Q3 = df_clean[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_extreme = Q1 - 1.5 * IQR
            upper_extreme = Q3 + 1.5 * IQR

            outliers = df_clean[(df_clean[col] < lower_extreme) | (df_clean[col] > upper_extreme)]
            n_outliers += len(outliers)

            df_clean = df_clean[(df_clean[col] >= lower_extreme) & (df_clean[col] <= upper_extreme)]

    print(f"Removed {n_outliers} outliers")
    print(f"Clean dataset shape: {df_clean.shape}")
    return df_clean

# Remove outliers from main numeric columns (focus on Price, Age, KM, Weight)
df_clean = outlier_capping(df, ['Price', 'Age_08_04', 'KM', 'Weight'])

# One-hot encoding for categorical
df_encoded = pd.get_dummies(df_clean, columns=['Fuel_Type', 'Automatic', 'Doors'], drop_first=True)

# Features and target
target_col = 'Price'
X = df_encoded.drop(columns=[target_col])
y = df_encoded[target_col]

print(f"\nFinal features shape: {X.shape}")

# train_test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Train: {X_train.shape}, Test: {X_test.shape}")

### BUILD 3 MODELS

# Model 1: FULL model
lr_full = LinearRegression()
lr_full.fit(X_train, y_train)

# Model 2: Main numeric features
main_features = ['Age_08_04', 'KM', 'HP', 'cc', 'Weight']
main_features = [f for f in main_features if f in X_train.columns]
lr_main = LinearRegression()
lr_main.fit(X_train[main_features], y_train)

# Model 3: Reduced (drop highly correlated cc)
reduced_features = [col for col in X_train.columns if col != 'cc']
lr_reduced = LinearRegression()
lr_reduced.fit(X_train[reduced_features], y_train)

print("\n MODEL COEFFICIENTS:")
print("Model 1 - Full (top 5):")
print(pd.DataFrame({'Feature': X_train.columns, 'Coef': lr_full.coef_}).sort_values('Coef', ascending=False).head())

### FIXED EVALUATION FUNCTION
def evaluate_model(name, model, X_tr, X_te, y_tr, y_te):
    y_tr_pred = model.predict(X_tr)
    y_te_pred = model.predict(X_te)

    # FIXED: RMSE
    rmse_tr = np.sqrt(mean_squared_error(y_tr, y_tr_pred))
    rmse_te = np.sqrt(mean_squared_error(y_te, y_te_pred))
    r2_tr = r2_score(y_tr, y_tr_pred)
    r2_te = r2_score(y_te, y_te_pred)

    print(f"\n{name}")
    print(f"  Train RMSE: {rmse_tr:.2f}")
    print(f"  Test  RMSE: {rmse_te:.2f}")
    print(f"  Train R²:   {r2_tr:.3f}")
    print(f"  Test  R²:   {r2_te:.3f}")
    return rmse_te, r2_te

# Evaluate 3 models
rmse1, r21 = evaluate_model("Model 1: Full LR", lr_full, X_train, X_test, y_train, y_test)
rmse2, r22 = evaluate_model("Model 2: Main numeric", lr_main, X_train[main_features], X_test[main_features], y_train, y_test)
rmse3, r23 = evaluate_model("Model 3: Reduced (no cc)", lr_reduced, X_train[reduced_features], X_test[reduced_features], y_train, y_test)

### LASSO & RIDGE
print("\n REGULARIZATION:")

lasso = Lasso(alpha=0.1, max_iter=10000, random_state=42)
lasso.fit(X_train, y_train)
evaluate_model("Lasso (alpha=0.1)", lasso, X_train, X_test, y_train, y_test)

ridge = Ridge(alpha=10, random_state=42)
ridge.fit(X_train, y_train)
evaluate_model("Ridge (aplha=10)", ridge, X_train, X_test, y_train, y_test)

### BEST MODEL SUMMARY
models = {
    "Full LR": (rmse1, r21),
    "Main numeric": (rmse2, r22),
    "Reduced": (rmse3, r23)}
best_model = min(models.items(), key=lambda x: x[1][0])
print(f"\n BEST MODEL: {best_model[0]} (Test RMSE: {best_model[1][0]:.2f}, R²: {best_model[1][1]:.3f})")