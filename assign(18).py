# -*- coding: utf-8 -*-
"""Assign(18).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NQ2Wn7cCukvTWT3nYqwSDUEs-0v38v3f
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

"""1. Data Exploration and Preprocessing"""

# Load dataset
data = pd.read_csv("sonardataset.csv", header=None)

print(data.head())
print(data.shape)
print(data.info())

# Features (first 60 columns)
X = data.iloc[:, :-1]

# Target (last column)
y = data.iloc[:, -1]

# Convert features to numeric (CRITICAL STEP)
X = X.apply(pd.to_numeric, errors='coerce')

# Check for missing values created during conversion
print(X.isnull().sum().sum())  # should be 0

# Encode target
encoder = LabelEncoder()
y = encoder.fit_transform(y)

# Feature scaling
scaler = StandardScaler()
X = scaler.fit_transform(X)

print("Feature scaling completed successfully!")

print(X.dtype)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""2. Model Implementation"""

# Build Neural Network
model = Sequential()

# Hidden layer
model.add(Dense(32, input_dim=60, activation='relu'))

# Output layer
model.add(Dense(1, activation='sigmoid'))

model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

"""60 inputs -> hidden layer

ReLU activation = fast learning

Sigmoid = binary classification

Adam optimizer = stable training
"""

# Train model
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=16,
    validation_split=0.2,
    verbose=1
)

# Evaluate model
loss, accuracy = model.evaluate(X_test, y_test)
print("Test Accuracy:", accuracy)

# Predictions
y_pred = (model.predict(X_test) > 0.5).astype(int)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""3. Hyperparameter Tuning"""

tuned_model = Sequential()

tuned_model.add(Dense(64, activation='relu', input_dim=60))
tuned_model.add(Dense(32, activation='relu'))
tuned_model.add(Dense(16, activation='relu'))
tuned_model.add(Dense(1, activation='sigmoid'))

tuned_model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

history_tuned = tuned_model.fit(
    X_train, y_train,
    epochs=150,
    batch_size=8,
    validation_split=0.2,
    verbose=1
)

# Evaluate
loss_tuned, acc_tuned = tuned_model.evaluate(X_test, y_test)
print("Tuned Model Accuracy:", acc_tuned)

# Compare results
print("Basic Model Accuracy:", accuracy)
print("Tuned Model Accuracy:", acc_tuned)

"""4. Performance Evaluation"""

print("\nConfusion Matrix:\n", classification_report(y_test,y_pred))

plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.legend()
plt.title("Training vs Validation Accuracy")
plt.show()

"""Evaluation Criteria :

- Data preprocessing correctness

- Proper ANN model design

- Hyperparameter tuning effort

- Clear evaluation metrics

- Model comparison & explanation

- Clean and reproducible code
"""