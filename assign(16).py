# -*- coding: utf-8 -*-
"""Assign(16).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w2qtMFf86YfFi3h2VUqkz-C_vxtMmd_O
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler

"""Data Preprocessing:"""

# 1. Load the dataset
df = pd.read_csv('anime.csv')

# 2. Handle missing values
# Some ratings might be missing (NaN). We fill them with the mean or drop them.
df['rating'] = df['rating'].fillna(df['rating'].mean())

# Drop rows where genres are missing as they are crucial for similarity
df = df.dropna(subset=['genre'])

print("Dataset Loaded and Cleaned.")
print(df.head())

"""Feature Extraction:"""

# 1. One-Hot Encode the 'genre' column
# Since one anime can have multiple genres, we split and get dummies
genres_dummies = df['genre'].str.get_dummies(sep=', ')

# 2. Normalize the numerical 'rating' feature
scaler = MinMaxScaler()
df['normalized_rating'] = scaler.fit_transform(df[['rating']])

# 3. Combine features for similarity calculation
# We combine the genre columns and the normalized rating
features = pd.concat([genres_dummies, df['normalized_rating']], axis=1)

print("Features Extracted and Normalized.")

"""Recommendation System:"""

# Compute the Cosine Similarity Matrix
# Note: For very large datasets, you might compute similarity on-the-fly to save memory
cosine_sim = cosine_similarity(features)

def get_recommendations(target_title, threshold=0.5):
    # Find the index of the anime that matches the title
    try:
        idx = df[df['name'] == target_title].index[0]
    except IndexError:
        return "Anime not found in dataset."

    # Get similarity scores for all anime with that target
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Filter by threshold and sort by score (highest first)
    sim_scores = [s for s in sim_scores if s[1] >= threshold and s[0] != idx]
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the top 10 recommended anime
    anime_indices = [i[0] for i in sim_scores[:10]]

    return df['name'].iloc[anime_indices]

# Test the system
print("\nRecommendations for 'Death Note':")
print(get_recommendations('Death Note', threshold=0.7))

"""Interview Questions:

1. Can you explain the difference between user-based and item-based collaborative filtering?

- User-Based: This method recommends items by finding similar users. If User A and User B both liked Death Note, and User A also likes Code Geass, the system will recommend Code Geass to User B.
- Item-Based: This method focuses on the similarity between items themselves. If most people who liked Naruto also liked One Piece, the system identifies these two as "similar" and recommends One Piece to anyone who watches Naruto

2. What is collaborative filtering, and how does it work?

- Definition: Collaborative filtering is a technique used by recommendation systems to make automatic predictions about a user's interests by collecting preferences from many users.

- How it works: It relies on the "wisdom of the crowd." It assumes that if a group of people agreed in the past (e.g., they all rated certain anime highly), they will likely agree in the future. It uses a matrix of user-item interactions (like ratings) to find patterns and fill in missing values to suggest new content.
"""