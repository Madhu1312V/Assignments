# -*- coding: utf-8 -*-
"""Assign(19).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xl1kep8CmWtuZXLo1itpqmfdKNG3lRHs
"""

import nltk
nltk.download('all')

import pandas as pd
import numpy as np
import re
import nltk
import matplotlib.pyplot as plt
from wordcloud import WordCloud

from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

nltk.download('stopwords')

"""1. Load Dataset"""

# Load TSV file
data = pd.read_csv("amazonreviews.tsv", sep="\t")

print("Dataset shape:", data.shape)
print(data.head())

"""2. Data Cleaning"""

# Remove duplicates
data.drop_duplicates(inplace=True)

# Remove missing values
data.dropna(inplace=True)

print("After cleaning:", data.shape)

# Text preprocessing function
stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = text.lower()                     # lowercase
    text = re.sub(r'[^a-z\s]', '', text)    # remove punctuation & numbers
    words = text.split()
    words = [w for w in words if w not in stop_words]
    return " ".join(words)

data['clean_review'] = data['review'].apply(clean_text)

""" 3. Exploratory Analysis"""

# Sentiment distribution
data['label'].value_counts().plot(kind='bar')
plt.title("Sentiment Distribution")
plt.show()

# Word cloud for positive reviews
positive_text = " ".join(data[data['label']=='pos']['clean_review'])
wordcloud_pos = WordCloud(width=800, height=400).generate(positive_text)

plt.imshow(wordcloud_pos)
plt.axis('off')
plt.title("Positive Reviews Word Cloud")
plt.show()

# Word cloud for negative reviews
negative_text = " ".join(data[data['label']=='neg']['clean_review'])
wordcloud_neg = WordCloud(width=800, height=400).generate(negative_text)

plt.imshow(wordcloud_neg)
plt.axis('off')
plt.title("Negative Reviews Word Cloud")
plt.show()

"""4. Feature Extraction (TF-IDF)"""

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(data['clean_review'])

y = data['label']

""" 5. Train/Test Split"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""6. Model Training"""

model = LogisticRegression()
model.fit(X_train, y_train)

"""7. Evaluation"""

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))